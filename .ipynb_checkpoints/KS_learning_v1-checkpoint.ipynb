{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWaFqLMXbUDa"
   },
   "source": [
    "**Problem 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "K7BmCK9BbWkp",
    "outputId": "57c56a24-e35f-4b08-f096-ee9f0393665e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statevector([0.70710678+0.j, 0.        +0.j, 0.        +0.j,\n",
      "             0.        +0.j, 0.        +0.j, 0.        +0.j,\n",
      "             0.        +0.j, 0.70710678+0.j],\n",
      "            dims=(2, 2, 2))\n",
      "Statevector([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "             0.+0.j],\n",
      "            dims=(2, 2, 2))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Useful additional packages \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, transpile\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "from qiskit import BasicAer\n",
    "from qiskit.quantum_info import Operator\n",
    "from qiskit.quantum_info import Statevector\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "q = QuantumRegister(2)\n",
    "\n",
    "qc = QuantumCircuit(q)\n",
    "qc.u(pi,0,pi,q[0])\n",
    "qc.draw()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#lets create GHZ state\n",
    "circ = QuantumCircuit(3)\n",
    "# Add a H gate on qubit 0, putting this qubit in superposition.\n",
    "circ.h(0)\n",
    "# Add a CX (CNOT) gate on control qubit 0 and target qubit 1, putting\n",
    "# the qubits in a Bell state.\n",
    "circ.cx(0, 1)\n",
    "# Add a CX (CNOT) gate on control qubit 0 and target qubit 2, putting\n",
    "# the qubits in a GHZ state.\n",
    "circ.cx(0, 2)\n",
    "# Set the intial state of the simulator to the ground state using from_int\n",
    "state = Statevector.from_int(0, 2**3)\n",
    "state1 = state.copy()\n",
    "# Evolve the state by the quantum circuit\n",
    "state = state.evolve(circ)\n",
    "print(state)\n",
    "print(state1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "KkAYQqj1tM1x",
    "outputId": "c0469ff4-6910-433f-aad1-77672e48c334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "#function that apply the KS test to two probability list\n",
    "def KS(P1, P2):\n",
    "    assert len(P1) == len(P2)\n",
    "    cdf1 = [P1[0]]\n",
    "    cdf2 = [P2[0]]\n",
    "    for i in range(len(P1)-1):\n",
    "        cdf1.append(cdf1[i] + P1[i+1])\n",
    "        cdf2.append(cdf2[i] + P2[i+1])\n",
    "    difference = torch.tensor(cdf1) - torch.tensor(cdf2)\n",
    "    #print(difference)\n",
    "    return difference.abs().max().item()\n",
    "\n",
    "print(KS([0.2, 0.8], [0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit.circuit.instructionset.InstructionSet at 0x7f87356900d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = QuantumRegister(3)\n",
    "qc = QuantumCircuit(q)\n",
    "qc.u(0.5,0,pi,q[0])\n",
    "qc.u(0.5,0,pi,q[1])\n",
    "qc.u(0.5,0,pi,q[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9960,  0.5384],\n",
      "        [-1.4568,  0.1620]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.randn(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters:  tensor([[3.0788, 1.2252, 1.2252],\n",
      "        [2.2619, 2.8274, 2.1677],\n",
      "        [0.7226, 1.5394, 0.1571]])\n",
      "Current Transformation:\n",
      "tensor([[ 0.0314+0.0000j, -0.3386+0.9404j],\n",
      "        [ 0.3386+0.9404j, -0.0242+0.0200j]])\n",
      "tensor([[ 0.4258+0.0000j,  0.5086+0.7484j],\n",
      "        [-0.8605+0.2796j,  0.1188-0.4089j]])\n",
      "tensor([[ 0.9354+0.0000j, -0.3491+0.0553j],\n",
      "        [ 0.0111+0.3533j, -0.1172+0.9281j]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Parameters:  tensor([[ 3.1366,  1.4248,  1.0008],\n",
      "        [ 3.1364,  3.0356,  1.9433],\n",
      "        [ 3.1253,  1.5579, -0.0673]])\n",
      " \n",
      "Current Transformation:\n",
      "tensor([[ 0.0025+0.0000j, -0.5396+0.8419j],\n",
      "        [ 0.1454+0.9894j, -0.0019+0.0016j]])\n",
      "tensor([[ 2.5830e-03+0.0000j,  3.6393e-01+0.9314j],\n",
      "        [-9.9438e-01+0.1058j,  6.8020e-04-0.0025j]])\n",
      "tensor([[ 8.1707e-03+0.0000j, -9.9770e-01-0.0673j],\n",
      "        [ 1.2847e-02+0.9999j,  6.5445e-04+0.0081j]])\n",
      " \n",
      "New vs Original State Vector:\n",
      "Statevector([0.70710678+0.j, 0.        +0.j, 0.        +0.j,\n",
      "             0.        +0.j, 0.        +0.j, 0.        +0.j,\n",
      "             0.        +0.j, 0.70710678+0.j],\n",
      "            dims=(2, 2, 2))\n",
      "Statevector([ 6.82426235e-01-0.18508001j, -7.07384929e-04-0.00161422j,\n",
      "              1.68778591e-03-0.00066035j, -1.44265179e-03-0.00559909j,\n",
      "             -1.58373975e-03-0.00555161j, -1.81662872e-03+0.00029479j,\n",
      "             -2.16269344e-04-0.00177812j,  6.82430737e-01-0.18506314j],\n",
      "            dims=(2, 2, 2))\n"
     ]
    }
   ],
   "source": [
    "#this is where we try to learn the symmetry\n",
    "\n",
    "\n",
    "class SymFinder():\n",
    "  def __init__(self, eta, step_size):\n",
    "    self.parameters = torch.randint(0, 100, (3, 3)) * pi /100\n",
    "    #parameters[i,0] is the theta for ith qubit, 1 is \\phi, 2 is lambda\n",
    "    self.original_state = state\n",
    "    self.transformed_state = None\n",
    "    self.lr = eta\n",
    "    self.reg = 10 # this is regularizer's coefficient.\n",
    "    self.step_size = step_size\n",
    "    self.losses = []\n",
    "\n",
    "  \n",
    "  #return a transformed state according to parameter\n",
    "  def transform(self, p):\n",
    "    q = QuantumRegister(3)\n",
    "    qc = QuantumCircuit(q)\n",
    "    qc.u(p[0,0].item(),p[0,1].item(),p[0,2].item(),q[0])\n",
    "    qc.u(p[1,0].item(),p[1,1].item(),p[1,2].item(),q[1])\n",
    "    qc.u(p[2,0].item(),p[2,1].item(),p[2,2].item(),q[2])\n",
    "    return self.original_state.copy().evolve(qc)\n",
    "\n",
    "\n",
    "  \n",
    "  def change_basis(self, state1, state2):\n",
    "    q = QuantumRegister(3)\n",
    "    qc = QuantumCircuit(q)\n",
    "    qc.u(pi/2, 0, 0, q[0])\n",
    "    qc.u(pi/2, 0, 0, q[1])\n",
    "    qc.u(pi/2, 0, 0, q[2])\n",
    "    return state1.copy().evolve(qc), state2.copy().evolve(qc)\n",
    "\n",
    "  #return the loss from KS test of original vs another state\n",
    "  def calculate_loss(self, state2):\n",
    "    #get the probability in the original basis\n",
    "    P1 = self.original_state.probabilities()\n",
    "    P2 = state2.probabilities()\n",
    "    #now we calculate probability in another basis\n",
    "    new_state1, new_state2 = self.change_basis(self.original_state, state2)\n",
    "    Q1 = new_state1.probabilities()\n",
    "    Q2 = new_state2.probabilities()\n",
    "    #lets add regularizer, punish u0 last coefficient being absolute value 1.\n",
    "    a = torch.abs(self.current_matrix()[0][1,1])\n",
    "    #print(a)\n",
    "    v = torch.exp(-(a-1)**2) * self.reg\n",
    "    #print(a, v)\n",
    "    return [KS(P1, P2) + KS(Q1, Q2) + v, KS(P1, P2) + KS(Q1, Q2)]\n",
    "  \n",
    "    \n",
    "  def update(self):\n",
    "    #calculate the gradient using good old finite difference:\n",
    "    cur_state = self.transform(self.parameters)\n",
    "    cur_loss = self.calculate_loss(cur_state)[0]\n",
    "    grad = torch.zeros(3,3)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            new_param = self.parameters.clone()\n",
    "            new_param[i,j] = new_param[i,j] + self.step_size\n",
    "            new_state = self.transform(new_param)\n",
    "            new_loss = self.calculate_loss(new_state)[0]\n",
    "            grad[i,j] = (new_loss - cur_loss) / self.step_size\n",
    "    #update the parameters:\n",
    "    self.parameters = self.parameters - self.lr * grad\n",
    "    #self.parameters[:, 2] = torch.zeros(3)\n",
    "    return self.calculate_loss(cur_state)[1]\n",
    "\n",
    "  def current_matrix(self):\n",
    "    p = self.parameters\n",
    "    #p[0,:] = torch.tensor([3.14159, 0,3.1415926])\n",
    "    u0 = torch.tensor([[torch.cos(p[0,0]/2), -torch.exp(-p[0,2]*1j)*torch.sin(p[0,0]/2)],\\\n",
    "                    [torch.exp(p[0,1]*1j)*torch.sin(p[0,0]/2), torch.exp((p[0,1] + p[0,2])*1j)*torch.cos(p[0,0]/2)]])\n",
    "    u1 = torch.tensor([[torch.cos(p[1,0]/2), -torch.exp(-p[1,2]*1j)*torch.sin(p[1,0]/2)],\\\n",
    "                    [torch.exp(p[1,1]*1j)*torch.sin(p[1,0]/2), torch.exp((p[1,1] + p[1,2])*1j)*torch.cos(p[1,0]/2)]])\n",
    "    u2 = torch.tensor([[torch.cos(p[2,0]/2), -torch.exp(-p[2,2]*1j)*torch.sin(p[2,0]/2)],\\\n",
    "                    [torch.exp(p[2,1]*1j)*torch.sin(p[2,0]/2), torch.exp((p[2,1] + p[2,2])*1j)*torch.cos(p[2,0]/2)]])\n",
    "    return [u0, u1, u2]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "  def train(self):\n",
    "    for i in range(700):\n",
    "      self.losses.append(self.update())\n",
    "      #print(self.losses[i])\n",
    "\n",
    "\n",
    "\n",
    "model = SymFinder(0.05, 0.01)\n",
    "#model.parameters = torch.tensor([[pi, 0, 3.0], [pi, 0, pi], [pi, 0, pi]])\n",
    "\n",
    "print(\"Current Parameters: \", model.parameters)\n",
    "\n",
    "print(\"Current Transformation:\")\n",
    "print(model.current_matrix()[0])\n",
    "print(model.current_matrix()[1])\n",
    "print(model.current_matrix()[2])\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(range(len(model.losses)), np.log10(model.losses))\n",
    "#plt.scatter(range(len(model.losses)), model.losses)\n",
    "plt.show()\n",
    "\n",
    "print(\"Current Parameters: \", model.parameters)\n",
    "print(\" \")\n",
    "print(\"Current Transformation:\")\n",
    "print(model.current_matrix()[0])\n",
    "print(model.current_matrix()[1])\n",
    "print(model.current_matrix()[2])\n",
    "print(\" \")\n",
    "print(\"New vs Original State Vector:\")\n",
    "print(model.original_state)\n",
    "print(model.transform(model.parameters))\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n",
      "tensor(1.0000-0.0024j)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(torch.pow(model.current_matrix()[2][:,0].abs(), 2).sum())\n",
    "print(model.current_matrix()[0][1,1] * model.current_matrix()[1][1,1] * model.current_matrix()[2][1,1])\n",
    "\n",
    "\n",
    "#plt.scatter(range(len(model.losses)), np.log10(model.losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-33-31d575f077ea>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-31d575f077ea>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(torch.exp(torch.tensor([3+3j]))\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "print(torch.exp(torch.tensor([3+3j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "90779316f194e2e5479652345a17af545355bf918319becd7e11a824792fc4d0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
